# AnÃ¡lise de InadimplÃªncia com Machine Learning

Este projeto implementa um modelo de machine learning para previsÃ£o de inadimplÃªncia utilizando Ã¡rvores de decisÃ£o. O modelo inclui tÃ©cnicas avanÃ§adas de tratamento de dados desbalanceados e validaÃ§Ã£o cruzada para garantir resultados robustos.

## ğŸ¯ Objetivo

O objetivo principal Ã© prever a probabilidade de inadimplÃªncia de clientes utilizando caracterÃ­sticas do histÃ³rico automotivo. O projeto implementa um classificador binÃ¡rio que pode identificar potenciais casos de inadimplÃªncia.

## ğŸ”§ TÃ©cnicas Implementadas

- **Modelo Base**: Ãrvore de DecisÃ£o (Decision Tree Classifier)
- **Tratamento de Dados Desbalanceados**:
  - SMOTE (Synthetic Minority Over-sampling Technique)
  - NearMiss (Under-sampling)
- **ValidaÃ§Ã£o**: 
  - K-Fold Cross Validation
  - Stratified K-Fold
- **MÃ©tricas de AvaliaÃ§Ã£o**:
  - AcurÃ¡cia
  - PrecisÃ£o
  - Recall
  - F1-Score
  - Curva ROC e AUC
  - Curva Precision-Recall
  - Matriz de ConfusÃ£o

## ğŸ“Š CaracterÃ­sticas do Modelo

- Profundidade mÃ¡xima da Ã¡rvore: 10
- ValidaÃ§Ã£o cruzada com 5 folds
- Conjunto de teste: 15% dos dados
- EstratificaÃ§Ã£o mantida durante o split dos dados

## ğŸ“‹ Requisitos

```python
pandas
scikit-learn
matplotlib
imbalanced-learn
```

## ğŸš€ Como Executar

1. Instale as dependÃªncias:
```bash
pip install pandas scikit-learn matplotlib imbalanced-learn
```

2. Certifique-se de que o arquivo 'emp_automovel.csv' estÃ¡ no diretÃ³rio do projeto

3. Execute o script principal:
```bash
python first.py
```

## ğŸ“ˆ Resultados

O modelo gera diversas visualizaÃ§Ãµes e mÃ©tricas:
- Matriz de confusÃ£o
- Curva ROC
- Curva Precision-Recall
- RelatÃ³rio de classificaÃ§Ã£o completo
- Intervalos de confianÃ§a para as mÃ©tricas

## ğŸ” CaracterÃ­sticas do Dataset

O dataset (`emp_automovel.csv`) contÃ©m informaÃ§Ãµes sobre emprÃ©stimos automotivos, incluindo a variÃ¡vel alvo 'inadimplente'.

## âš–ï¸ Balanceamento de Classes

O projeto implementa duas abordagens para lidar com o desbalanceamento de classes:
1. **Oversampling** com SMOTE: Cria amostras sintÃ©ticas da classe minoritÃ¡ria
2. **Undersampling** com NearMiss: Reduz as amostras da classe majoritÃ¡ria

## ğŸ“ Notas Adicionais

- O modelo utiliza pipeline para garantir que nÃ£o haja vazamento de dados durante o processo de validaÃ§Ã£o cruzada
- ImplementaÃ§Ã£o de intervalos de confianÃ§a para avaliar a robustez do modelo
- VisualizaÃ§Ãµes detalhadas para anÃ¡lise de performance